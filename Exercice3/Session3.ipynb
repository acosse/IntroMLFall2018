{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Session III"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During this session, we will learn how to use unsupervised methods. \n",
    "You already started using some of them in the homework. The session is organized around 3 main exerices. It is suggested to complete the exercices in the following order: 1 (including 1.1,1.2),3.1,2,3.2 and then 1.3.\n",
    "\n",
    "- __Exercice 1__ focuses on various applications of ICA ranging from medicine to finance, including speech processing.\n",
    "- __Exercice 2__ uses manifold learning to extract a lower dimensional representation from a short movie\n",
    "- __Exercice 3__ uses hierarchical clustering to extract information from the genetic expression of cancerous cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Independent Component Analysis, seizure prediction, sound source separation and market analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this first exercice, we will consider three applications of independent component analysis. \n",
    "- In the __first application__, we will use ICA to remove artefacts from EEG signals, this is useful in the understanding of cognitive processes or to predict and detect abnormal activity such as in epileptic seizure. \n",
    "- In the __second application__, we will use ICA to extract a conversation from some background (music) noise\n",
    "- In the third exercice, we will use ICA to extract latent factors from financial data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Cleaning EEG from occular artefacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sources: \n",
    " - https://martinos.org/, \n",
    " - JUNG et al.,Removing electroencephalographic artifacts by blind source separation,\n",
    " - C Brunner, Removing eye activity from EEG signals via ICA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercice we will use ICA to separate the sources in an EEG signal. In particular, we will extract the electric signal arising from eye movements. \n",
    "\n",
    "When doing an EEG we are usually interested in understanding and comparing the behavior of populations of neurons across the brain. EEG recordings have also been assesed as objective markers of consciousness (see Q.Noirhomme and S Laureys, \"Consciousness and Unconsciousness:\n",
    "An EEG Perspective\", http://journals.sagepub.com/doi/pdf/10.1177/1550059413519518)\n",
    "\n",
    "The electrode map is pretty standard (see below for an example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"mapEEG1.PNG\" height=\"250\" width=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is to identify the location/geography of each EEG signal. Then one approach is to count the number of peaks (cycles) within a given time interval. One of the things we might want to study is reactivity. I.e if you pinch someone, the EEG is supposed to get faster. More generally, we are interested in responses to stimulations, pain, ligth,..\n",
    "As an example, when you hyperventilate, CO2 goes down with cerebral blood flow and you see a slowing of EEG. Such slowing is normal but if you see slowing on only one side of the brain and not the other that might reveal vascular insufficiency on that particular side. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are thus interested in the neurons spikes. However, EEG recordings are often corrupted with distracting artifacts such as eye movements, eye blinks, muscle noise, heart signals,.. Such artifacts present serious problems for EEG interpretation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercice, we will use the MNE API (https://martinos.org/mne/stable/index.html) which is used for neurophysiological data analysis. The lines below are storing the data after some preprocessing inside the variable __raw_tmp__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5\n",
    "from scipy.io import loadmat\n",
    "import mne\n",
    "# importing ICA\n",
    "from mne.preprocessing import ICA\n",
    "\n",
    "mat = loadmat(\"A01T.mat\")\n",
    "eeg = mat[\"data\"][0, 3][\"X\"][0, 0] * 10e-6\n",
    "\n",
    "# you can compare the names below \n",
    "\n",
    "ch_names = [\"Fz\", \"FC3\", \"FC1\", \"FCz\", \"FC2\", \"FC4\", \"C5\", \"C3\", \"C1\", \"Cz\",\n",
    "            \"C2\", \"C4\", \"C6\", \"CP3\", \"CP1\", \"CPz\", \"CP2\", \"CP4\", \"P1\", \"Pz\",\n",
    "            \"P2\", \"POz\", \"EOG1\", \"EOG2\", \"EOG3\"]\n",
    "\n",
    "info = mne.create_info(ch_names, 250, ch_types=[\"eeg\"] * 22 + [\"eog\"] * 3)\n",
    "raw = mne.io.RawArray(eeg.T, info)\n",
    "\n",
    "raw.set_montage(mne.channels.read_montage(\"standard_1020\"))\n",
    "# removing low frequencies\n",
    "raw_tmp = raw.copy()\n",
    "raw_tmp.filter(1, None, fir_design=\"firwin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Start by creating an ICA object (ICA)\n",
    "- fit the object to your variable raw_tmp\n",
    "- use the function plot_components from the ICA object with argument \"inst=raw_data\" in order to represent each of the ICA components in an interactive fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When computing the independent components, we also compute the \"loadings\" that is how much each independent component contribute to the signal from each electrode. One can then map this decomposition onto the skull to understand the spatial evolution of each if the independent components. This is what you see in the above figures. \n",
    "\n",
    "We will now remove the component corresponding to the eye movement.\n",
    "\n",
    "- __According to you, and looking at the figure you generated, what component is the most likely to represent ocular motion?__\n",
    "- Click on the subplot corresponding to the corresponding component to get more details on this component. \n",
    "\n",
    "When considering neural activity signals, you should in general observe a characteristic \"alpha\" peak. This is an additional indication of a component which is independent from occular activity (see the figure below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"EEGalphaPeak.jpg\" height=\"300\" width=\"300\">\n",
    "\n",
    "source: Relationships between electroencephalographic spectral peaks across frequency bands\n",
    "S. J. van Albada1,2,3* and P. A. Robinson2,3,4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this information, what component is likely to encode occular motion according to you ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function \"plot_sources\" from the MNE implementation of ICA, display the EEG recordings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your code here \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you see any signal that would be significantly different from the others?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the function \"exclude\" from mne.ICA, remove the component that looks different to you\n",
    "- Finally visualize the result by using the following two steps\n",
    "\n",
    "    - Create a copy of the original data with raw.copy()\n",
    "    - Use the \"apply\" function from your ICA object to get clean the signals from the occular component \n",
    "    - Plot the raw signals together with the function plot from both (1) the raw signal and (2) the corrected one. What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Traditional coktail party: the semblance of privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(sound sources: http://sound.media.mit.edu/ica-bench/sources/)\n",
    "\n",
    "In this second exercice, we will use ICA to extract individual conversations from the recording of mixed sounds. Source separation is a popular application of independent component analysis. It also shows how fragile/idealized the scene from the movie \"The Firm\" is, when Tom Cruise turns on the music to reveal to his wife, played by Jeanne Tripplehorn, that the law firm for which he works, is led by the mafia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import scipy\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import FastICA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the snippet below to load the two independent sounds and listen to those sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fs_1, sound1 = wavfile.read(\"mike.wav\")\n",
    "fs_2, sound2 = wavfile.read(\"beet92.wav\")\n",
    "# reshaping the files to have same size\n",
    "m, = sound1.shape \n",
    "sound2 = sound2[:m]\n",
    "\n",
    "# plotting time domain representation of signal\n",
    "figure_1 = plt.figure(\"Original Signal\")\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title(\"Time Domain Representation of voice_1\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Signal\")\n",
    "plt.plot(sound1)\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title(\"Time Domain Representation of voice_2\")\n",
    "plt.plot(sound2)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Signal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines below are used to mix the sounds. Run those lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix data\n",
    "mixed = np.c_[sound1, sound2]\n",
    "A = np.array([[1, 0.5], [0.5, 1]])\n",
    "X = np.dot(mixed, A)\n",
    "\n",
    "# plotting time domain representation of mixed signal\n",
    "figure_2 = plt.figure(\"Mixed Signal\")\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title(\"Time Domain Representation of mixed voice_1\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Signal\")\n",
    "plt.plot(X[:, 0])\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title(\"Time Domain Representation of mixed voice_2\")\n",
    "plt.plot(X[:, 1])\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Signal\")\n",
    "\n",
    "scipy.io.wavfile.write('mixed1.wav', fs_1, X[:,0])\n",
    "scipy.io.wavfile.write('mixed2.wav', fs_1, X[:,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by listening to the mix. Given the mixed signals stored in X, use FastICA function to recover the sources. Hint(s): \n",
    "- Start by initializing a FastICA object \n",
    "- Fit the ica object to the data\n",
    "- Transform the data, using your ICA object and store the result in a new variable\n",
    "- plot the resulting two signals (those correspond to the first and second columns in the ouptut of your ICA fit)\n",
    "-then store those signals as .wav files as we did above. Listen to them. Can you understand anything? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here\n",
    "\n",
    "\n",
    "\n",
    "scipy.io.wavfile.write('recovered1.wav', fs_1, 4*S_[:, 0])\n",
    "scipy.io.wavfile.write('recovered2.wav', fs_1, 2*S_[:, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Searching for hidden factors in financial time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(source1: A Hyvarinen, E. Oja, Independent Component Analysis: A Tutorial \n",
    " source2: see for example, A. D. Back and A. S. Weigend, A First Application of Independent Component Analysis to Extracting\n",
    "Structure from Stock Returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercice, you will be given the opportunity to apply ICA to multivariate financial time series such as a portfolio of stocks. In finance, one is usually interested in understanding what drives the motion of a financial time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pd.core.common.is_list_like = pd.api.types.is_list_like\n",
    "from pandas_datareader import data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2016-12-31'\n",
    "\n",
    "from pandas_datareader import data as pdr\n",
    "import fix_yahoo_finance as yf\n",
    "yf.pdr_override()\n",
    "data1 = pdr.get_data_yahoo(\"GOOG\", start=\"2017-01-01\", end=\"2018-10-1\")\n",
    "data1 = data1['Close']\n",
    "data2 = pdr.get_data_yahoo(\"NVDA\", start=\"2017-01-01\", end=\"2018-10-1\")\n",
    "data2 = data2['Close']\n",
    "data3 = pdr.get_data_yahoo(\"FB\", start=\"2017-01-01\", end=\"2018-10-1\")\n",
    "data3 = data3['Close']\n",
    "data4 = pdr.get_data_yahoo(\"AAPL\", start=\"2017-01-01\", end=\"2018-10-1\")\n",
    "data4 = data4['Close']\n",
    "data5 = pdr.get_data_yahoo(\"IBM\", start=\"2017-01-01\", end=\"2018-10-1\")\n",
    "data5 = data5['Close']\n",
    "data6 = pdr.get_data_yahoo(\"MSFT\", start=\"2017-01-01\", end=\"2018-10-1\")\n",
    "data6 = data6['Close']\n",
    "data7 = pdr.get_data_yahoo(\"INTC\", start=\"2017-01-01\", end=\"2018-10-1\")\n",
    "data7 = data7['Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the snippet from the first homework, plot the time series for each company\n",
    "\n",
    "- Using the same ICA approach we used for the EEG signals, compute the principal components of the time series. How many components are need to capture most of the trend ?\n",
    "\n",
    "- Repeat the analysis with principal components. How many components do you need?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Manifold learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercice, we will study how, in a very simple framework, one can use the manifold underlying a set of images to denoise those images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for this exercice is a collection of noisy images of the number 2\n",
    "<img src=\"rotation2.png\" height=\"350\" width=\"350\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use this snippet to import the rotated images. The piece of code just load the sequence of images and store \n",
    "## it into a numpy array\n",
    "\n",
    "import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "#img=mpimg.imread('your_image.png')\n",
    "\n",
    "\n",
    "filelist = glob.glob('manifold2/*.png')\n",
    "x = np.array([np.array(Image.open(fname)) for fname in filelist])\n",
    "imgplot = plt.imshow(x[1,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-Dimensional Scaling (MDS) is a non linear dimensionality reduction approach that is used to \n",
    "It relies on the following steps\n",
    "\n",
    "- Compute the proximity matrix $D_{ij} = \\|\\boldsymbol{x}_i-\\boldsymbol{x}_j\\|^2$ (in classical Multidimensional scaling,w e assume Euclidean distances)\n",
    "\n",
    "- Apply double centering to this matrix, through $D\\leftarrow -\\frac{1}{2}CDC$, using the matrix $C = \\text{Id} - \\frac{1}{n}\\boldsymbol{1}\\boldsymbol{1}^T$ where $\\text{Id}$ is the identity matrix, $n$ is the number of images and $\\boldsymbol{1}$ is a vector of all $1's$.\n",
    "\n",
    "- Compute the eigenvalue decomposition of the matrix $D$. In this case the sequence of images has a latent representation with no more than 2 degrees of freedom (the images are rotating inside a fixed 2D plane), and we will therefore only keep the largest 2 eigenvalues and the corresponding eigenvectors to derive the lower dimensional representation\n",
    "\n",
    "- The coordinates of your points in the 2D space are defined from the eigenvalue decomposition, $D = U\\Sigma U^T$. I.e if we let $U_2$ and $\\Sigma_2$ to denote the matrices encoding the first two eigenvectors and eigenvalues, the coordinates in the 2D space are defined as $X_{2D} = U_2\\Sigma_2^{1/2}$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Write your own implementation of MDS for the dataset below. display the 2D embedding. What do you see?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bonus:__ Use the embedding to denoise the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exerice, we will first use the scipy implementations for "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.1__ In this part, you will use hierarchical clustering on a collection of gene expressions measured on cancer cells. This time we will use the clustering functions from scipy. We will need both the \"linkage\" as well as the \"dendrogram\" implementations from scipy. The first one will be used to build the cluters, the second to represent those clusters at each step, as a tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "labelCells = pd.read_csv(\"NCI60_labs.csv\", index_col = 0)\n",
    "geneticDataCells = pd.read_csv(\"NCI60_data.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NCI60 dataset consists of measurements of 6,830 gene expressions on 64 cancer cells. Cancer types are stored in the variable \"geneticDataCells\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we will ignore those labels and just do unsupervised clustering on the data. \n",
    "\n",
    " - Using the function \"linkage\" from scipy (see above), get the each of the clusters (at eahc level of the hierarchy)\n",
    "\n",
    " - Using the output of the linkage function that you obtained in step 1., plot the corresponding dendrograms for the three types of linkage we studied in class. To plot the dendrogram, you can use the function \"dendrogram\" giving it as argument the output of \"linkage\" clustering together with the labels which are stored in \"labelCells\". Finally, for clarity you should set the parameter \"leaf_rotation\" to \"90\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.2__ Now start from the same dataset and write your own implementation of any of the linkage algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your code here\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
