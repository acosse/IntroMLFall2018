{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Lab 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Getting to know basic libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using numpy, start by generating a set of points $y$ satisfying \n",
    "    \\begin{align}\n",
    "        y_i = 2\\cos(x_i)\\sin(x_i) + 0.1\\varepsilon\n",
    "    \\end{align}\n",
    "    with 100 equispaced points $x_i\\in [0,10]$ where $\\varepsilon$ is normally distributed with mean $0$ and variance $1$. Then randomly select $20$ points on the interval (not necessarily amon the $x_i$) and compute their value $y$ (hint: use the functions $\\texttt{rand}$ and $\\texttt{randn}$ form numpy). Plot the samples on top of the function $y(x)$ using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add your code here. Generate noisy samples from the function 2*sin(x)cos(x). Plot the samples on top of the function\n",
    "# using matplotlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Still using numpy, compute, the mean and variance of the iris sepallength dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "iris = np.genfromtxt(url, delimiter=',', dtype='object')\n",
    "sepallength = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the pandas library to load and process datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Handmade regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using more advanced dataset and built in methods from scikit-learn, \n",
    "we will derive the regression coefficients by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code source: Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "\n",
    "# Use only one feature\n",
    "diabetes_X = diabetes.data[:, np.newaxis, 2]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X[:-20]\n",
    "diabetes_X_test = diabetes_X[-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = diabetes.target[:-20]\n",
    "diabetes_y_test = diabetes.target[-20:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using the formula for direct derivation of the regression coefficients, compute the expression \n",
    "for the regression line. (The formula can be derived from setting the derivative of the RSS criterion to zero)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot outputs\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\n",
    "\n",
    "# plot the line here \n",
    "\n",
    "\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Predicting housing prices in NYC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by creating yourself an account on Kaggle\n",
    "Then download the NYC property sales dataset on https://www.kaggle.com/new-york-city/nyc-property-sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace the link below with the link on your own computer to load the dataset\n",
    "\n",
    "path = \"/Users/acosse/Downloads/nyc-rolling-sales.csv\"\n",
    "nyc_data = pd.read_csv(path)\n",
    "\n",
    "\n",
    "\n",
    "# 1) start by displaying the labels of the data stored in nyc_data with the function list \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "[321.  22.  77. ... 307. 111.  56.]\n"
     ]
    }
   ],
   "source": [
    "# We will have to replace labels with white space and remove all white space for \n",
    "# later processing\n",
    "\n",
    "nyc_data.columns = nyc_data.columns.str.replace(' ', '')\n",
    "\n",
    "# 2. Extract the data corresponding the 'GREENWICH VILLAGE-CENTRAL' neighborhood and remove \n",
    "# all properties that have more than 1 unit\n",
    "\n",
    "\n",
    "# 3. remove all units that were sold for less than $100. Finally convert the \n",
    "# remaining SALEPRICE colum into a numerical array by using the .values function\n",
    "\n",
    "\n",
    "# 4. To do regression on the GREENWICH VILLAGE-CENTRAL properties, we want to extract \n",
    "# the sale dates for all those properties. So apply the same selection you applied on the price \n",
    "# column to the sale column\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 5. You are now left with a numeric array for the prices but the dates have a specific format.\n",
    "# Use the function .to_datetime to turn the dates into numeric values\n",
    "\n",
    "\n",
    "\n",
    "# 6. To do regression, we want to convert the dates into time differences. \n",
    "# Fortunately it can be done very easily. Start by computing the difference between \n",
    "# the date array you got from .to_datetime and the min of this array and display the result. \n",
    "# What do you see ?\n",
    "\n",
    "\n",
    "# 7. Extract the value with the .values function and store the result in a matYear1 array. \n",
    "# Then use the following lines to store the day differences as numbers\n",
    "\n",
    "\n",
    "matYear1 = matYear1 / pd.Timedelta(1, unit='d')\n",
    "matYear1.astype('timedelta64[D]')\n",
    "\n",
    "# remove all remaining erroneous values such as ' - ' and make sure the result is integer \n",
    "# by using the map function\n",
    "\n",
    "\n",
    "\n",
    "# 8. Learn the linear regression model from scikit-learn mapping the days difference to the price\n",
    "# (first without any training-test split)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 9 Compare your prediction with the true prices and plot the result as a scatter plot\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1. Predicting (or trying to) property prices in the village"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Now that your data is ready, split the time series between a training set and a test set \n",
    "# (here you need to do it manually as we want to use values up to a certain time to predict \n",
    "# values after that time)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Train the regression model and output the predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. plot your predictions as a scatter plot and as a time series and compare them to the true values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#4. Repeat steps 2. and 3. above now using quadratic data \n",
    "# (you can use the PolynomialFeatures and Pipeline modules from scikit-learn)\n",
    "# (hint: check the Underfitting vs. Overfitting example from scikit learn)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Predicting housing prices in Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download the Boston dataset \n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "\n",
    "# 1) display the keys, feature_names and shape of the dataset (hint: use the keys, feature_names and DESCR function of the \n",
    "# dataset)\n",
    "\n",
    "boston.keys()\n",
    "\n",
    "boston.data.shape()\n",
    "\n",
    "\n",
    "# 2) convert the dataset to a Pandas DataFrame and replace the headers \n",
    "# with the feature_names from the original dataset\n",
    "\n",
    "bos = pd.DataFrame(boston.data)\n",
    "bos.head()\n",
    "\n",
    "bos.columns = boston.feature_names\n",
    "bos.head()\n",
    "\n",
    "# 3) the prices are encoded in boston.target. Create a new column with \n",
    "# feature 'PRICE' in your pandas data frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Fitting the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1) Import the LinearRegression module from scikit-learn and \n",
    "# create a LinearRegression object \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = bos.drop('PRICE',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2) Use X as your input data and price as your output data to fit the \n",
    "# linear regession model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now have a regression model with a number of coefficients equal to the number of features you had in the original Pandas dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3) create a Pandas data Frame with first column equal to the features \n",
    "# labels and second column equal to the regression coeffcients. What do you see? which feature \n",
    "# has the highest correlation to the prices?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4) plot the sample points as pairs (highest correlation feature, price) using the scatter function from \n",
    "#    matplotlib\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2. Prediction and the MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1) Using the predict function from your linear regression model, to predict new labels y \n",
    "# from your data points (i.e each feature)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2) generate the scatter plot of the pairs (Y_true, Y_predicted). What do you see?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3) Compute the mean square error (MSE) recall that MSE = E{(true - predicted)^2}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 4) Create a new regression model with a single feature (for example the pupil teacher ratio)\n",
    "# compute the predicted prices for this new regression model and compute the MSE. What do you see?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3. Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn provides a special function to split a dataset between a training set and a test set randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1) Using the function train_test_split from scikit-learn, split your dataset between a \n",
    "training part and a test part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "2) Train a regression model on the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Compute the MSE on the training and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Finally, using the scatter function from matplotlib, plot the residuals (i.e predicted - true) \n",
    "on the test and training sets (superimpose them on the same plot with different colors)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4. Adding regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat step 3.1 but now with the Ridge regression and LASSO regression models from scikit-learn (see http://scikit-learn.org/stable/modules/linear_model.html) and plot your regression coefficients for various values of alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat step 3.1 with polynomial feature of degree 2 (hint: check the Underfitting vs. Overfitting example from scikit learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Classification can be done in a similar way as regression by using a linear model. \n",
    "If we have two classes, the idea is then to view the lienar model as encoding the probability of \n",
    "belonging to each class, or more simply have it assign a $\\pm 1$ label depending on whether we are in \n",
    "class $C_1$ or $C_2$    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1) You can very easily generate your own dataset in scikit-learn with the function make_classification.\n",
    "Use this function to create a two classes dataset with two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Train the LinearSVC and logistic regression classifiers on your dataset (use the function fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) The two models from scikit-learn output labels corresponding to each of the classes. Use the scatter function to plot the points from your dataset and then represent on top of \n",
    "those points, the splitting of the space obtained from the classifiers. \n",
    "\n",
    "- First generate a grid of points spanning the space between the min and max values of your data set\n",
    "\n",
    "- Then use the predict_proba functions of your classifiers to output the labels and plot the results using the contour function from pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min0 = min(X1[:,0])\n",
    "max0 = max(X1[:,0])\n",
    "min1 = min(X1[:,1])\n",
    "max1 = max(X1[:,1])\n",
    "\n",
    "xx, yy = np.mgrid[min0:max0:.01, min1:max1:.01]\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Multiple classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Generate a new three classes (or more) dataset with make_classification. How would you classify the data? Play on the number of feature and look at the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Train the LinearSVC classifier from scikit-learn svm on this new data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Modify the following lines to plot your classifier and the original training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line = np.linspace(-3,3,50)\n",
    "\n",
    "\n",
    "for coeff, interp, color in zip(separatingPlane.coef_,separatingPlane.intercept_, ['b','r', 'g']):\n",
    "\n",
    "\tax[0].plot(line, -(line*coeff[0] + interp) /coeff[1], c=color)\n",
    "\n",
    "\n",
    "\n",
    "mglearn.plots.plot_2d_classification(separatingPlane, X3, fill=True, alpha=.7)\n",
    "\n",
    "ax[1].scatter(X3[:,0],X3[:,1],marker='o', c=Y3,\n",
    "            s=25, edgecolor='k')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 One vs rest and one vs one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Instead of using LinearSVC, classify your data with the one vs rest and one vs one \n",
    "approaches (possibly with a majority vote). Compare your results to LinearSVC, what do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
